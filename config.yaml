train_data_dir: ./data/pu100_t3/train
val_data_dir: ./data/pu100_t3/val
train_subset: 100
val_subset: 10

model: transformer

hidden_dim: 128
num_layers: 4     
nhead: 16
latent_dim: 4  
dropout: 0.1

learning_rate: 0.0001  
weight_decay: 0.0001   
epochs: 50
batch_size: 4
num_workers: 4

scheduler_gamma: 0.5
scheduler_milestones: [15, 30, 40]

early_stopping_patience: 15

gradient_clip_val: 1.0
gradient_clip_algorithm: norm
accumulate_grad_batches: 8
check_val_every_n_epoch: 5
precision: 16

oc_q_min: 0.1
oc_s_B: 5.0

loss_weight_attractive: 1.0
loss_weight_repulsive: 1.0
loss_weight_beta: 1.0

output_dir: ./output
save_every: 10
resume: null

seed: 42
num_cpu_threads: 64
gpus: 2

dbscan_eps: 0.1  # Optimal for trained model
dbscan_min_samples: 2

purity_threshold: 0.75
eta_cut: null

pt_bins_start: 0.5
pt_bins_end: 2.0
pt_bins_count: 50
eta_bins_start: -4
eta_bins_end: 4
eta_bins_count: 50

epsilon_validation_values: [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.15, 0.2, 0.5, 1.0]